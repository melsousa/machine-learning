{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "\n",
        "# Carregando os dados\n",
        "df_vehicle = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/AM/lista-2/vehicle.csv\")\n",
        "\n",
        "# Dividindo os dados em características (X) e rótulo (y)\n",
        "X_vehicle = df_vehicle.iloc[:, :-1].values  # 18 primeiras colunas são características\n",
        "y_vehicle = df_vehicle.iloc[:, -1].values  # Última coluna é a saída\n",
        "\n",
        "# Codificando as classes como números inteiros\n",
        "label_encoder = LabelEncoder()\n",
        "y_vehicle_encoded = label_encoder.fit_transform(y_vehicle).reshape(-1, 1)\n",
        "\n",
        "# One-hot encoding dos rótulos\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "y_vehicle_one_hot = one_hot_encoder.fit_transform(y_vehicle_encoded)\n",
        "\n",
        "# Normalizando os dados de entrada\n",
        "X_normalized_vehicle = (X_vehicle - X_vehicle.min(axis=0)) / (X_vehicle.max(axis=0) - X_vehicle.min(axis=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-ctdBCHBiei",
        "outputId": "53c47d08-470c-43fe-b81e-953efa2a4b64"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para calcular média e desvio padrão\n",
        "def mean_std(values):\n",
        "    return np.mean(values), np.std(values)\n",
        "\n",
        "# Função de ativação sigmoidal\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "# Função de previsão\n",
        "def predict(X, weights, bias):\n",
        "    z = np.dot(X, weights) + bias\n",
        "    return sigmoid(z)\n"
      ],
      "metadata": {
        "id": "OjtuJEwDBqII"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient Descent\n",
        "def gradient_descent(X, y, weights, bias, learning_rate, iterations):\n",
        "    n = float(len(X))\n",
        "    for i in range(iterations):\n",
        "        y_pred = predict(X, weights, bias)\n",
        "        error = y - y_pred\n",
        "        gradient_weights = -np.dot(X.T, error) / n\n",
        "        gradient_bias = -np.mean(error)\n",
        "        weights -= learning_rate * gradient_weights\n",
        "        bias -= learning_rate * gradient_bias\n",
        "    return weights, bias\n"
      ],
      "metadata": {
        "id": "enDR8xTkBtev"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stochastic Gradient Descent\n",
        "def stochastic_gradient_descent(X, y, weights, bias, learning_rate):\n",
        "    n = float(len(X))\n",
        "    for i in range(len(X)):\n",
        "        x_i = X[i]\n",
        "        y_i = y[i]\n",
        "        y_pred = predict(x_i, weights, bias)\n",
        "        error = y_i - y_pred\n",
        "        gradient_weights = -x_i.reshape(-1,1) * error\n",
        "        gradient_bias = -error\n",
        "        weights -= learning_rate * gradient_weights\n",
        "        bias -= learning_rate * gradient_bias\n",
        "    return weights, bias"
      ],
      "metadata": {
        "id": "VPxXWCv8Bz5R"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para avaliação do modelo\n",
        "def evaluate_model(X_train, y_train, X_test, y_test, learning_rate, iterations, optimizer):\n",
        "    # Inicializando os pesos e o viés\n",
        "    weights = np.zeros((X_train.shape[1], y_train.shape[1]))\n",
        "    bias = np.zeros(y_train.shape[1])\n",
        "\n",
        "    # Selecionando o algoritmo de otimização\n",
        "    if optimizer == 'gd':\n",
        "        weights, bias = gradient_descent(X_train, y_train, weights, bias, learning_rate, iterations)\n",
        "    elif optimizer == 'sgd':\n",
        "        weights, bias = stochastic_gradient_descent(X_train, y_train, weights, bias, learning_rate)\n",
        "\n",
        "    # Fazendo previsões no conjunto de teste\n",
        "    y_pred = predict(X_test, weights, bias)\n",
        "    y_pred_binary = (y_pred == y_pred.max(axis=1, keepdims=True)).astype(int)\n",
        "\n",
        "    # Calculando acurácia global\n",
        "    accuracy = np.mean(np.all(y_pred_binary == y_test, axis=1))\n",
        "\n",
        "    # Calculando a acurácia por classe\n",
        "    class_accuracies = []\n",
        "    for i in range(y_test.shape[1]):\n",
        "        class_accuracy = np.mean((y_pred_binary[:, i] == y_test[:, i])[y_test[:, i] == 1])\n",
        "        class_accuracies.append(class_accuracy)\n",
        "\n",
        "    return accuracy, class_accuracies\n"
      ],
      "metadata": {
        "id": "ZpkdXWHWB7Ns"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo Hiperparâmetros\n",
        "learning_rate = 0.1\n",
        "iterations = 100\n",
        "n_folds = 10\n",
        "\n",
        "# Validação cruzada\n",
        "def cross_validate(X, y, n_folds, learning_rate, iterations, optimizer):\n",
        "    fold_size = len(X) // n_folds\n",
        "    accuracies = []\n",
        "    class_accuracies_list = []\n",
        "\n",
        "    for fold in range(n_folds):\n",
        "        start = fold * fold_size\n",
        "        end = start + fold_size\n",
        "\n",
        "        X_test = X[start:end]\n",
        "        y_test = y[start:end]\n",
        "\n",
        "        X_train = np.concatenate((X[:start], X[end:]), axis=0)\n",
        "        y_train = np.concatenate((y[:start], y[end:]), axis=0)\n",
        "\n",
        "        accuracy, class_accuracies = evaluate_model(X_train, y_train, X_test, y_test, learning_rate, iterations, optimizer)\n",
        "        accuracies.append(accuracy)\n",
        "        class_accuracies_list.append(class_accuracies)\n",
        "\n",
        "    mean_accuracy = np.mean(accuracies)\n",
        "    mean_class_accuracies = np.mean(class_accuracies_list, axis=0)\n",
        "\n",
        "    std_accuracy = np.std(accuracies)\n",
        "    std_class_accuracies = np.std(class_accuracies_list, axis=0)\n",
        "\n",
        "    return mean_accuracy, mean_class_accuracies, std_accuracy, std_class_accuracies\n",
        "\n"
      ],
      "metadata": {
        "id": "j7a0MaPXszdo"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Executando a validação cruzada\n",
        "mean_accuracy, mean_class_accuracies, std_accuracy, std_class_accuracies = cross_validate(X_normalized_vehicle, y_vehicle_one_hot, n_folds, learning_rate, iterations, 'gd')\n",
        "\n",
        "print('Gradient Descent')\n",
        "print(f\"Média Global: {mean_accuracy}\")\n",
        "print(f\"Desvio Padrão Global: {std_accuracy}\")\n",
        "for i in range(len(mean_class_accuracies)):\n",
        "    print(f\"Média da Acurácia para Classe {i}: {mean_class_accuracies[i]}\")\n",
        "    print(f\"Desvio Padrão da Acurácia para Classe {i}: {std_class_accuracies[i]}\")\n",
        ""
      ],
      "metadata": {
        "id": "uDgjSxp5A4Nj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2056ed39-545e-492e-d7f0-88aabaacaa15"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Descent\n",
            "Média Global: 0.42738095238095236\n",
            "Desvio Padrão Global: 0.0695079075095\n",
            "Média da Acurácia para Classe 0: 0.3746525234025234\n",
            "Desvio Padrão da Acurácia para Classe 0: 0.09696582956291487\n",
            "Média da Acurácia para Classe 1: 0.29411698276148407\n",
            "Desvio Padrão da Acurácia para Classe 1: 0.19155185790623847\n",
            "Média da Acurácia para Classe 2: 0.5921285435713515\n",
            "Desvio Padrão da Acurácia para Classe 2: 0.18743012236688475\n",
            "Média da Acurácia para Classe 3: 0.5212723598211214\n",
            "Desvio Padrão da Acurácia para Classe 3: 0.12751958590310258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Descent"
      ],
      "metadata": {
        "id": "uR8X7xOwHAlR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stochastic Gradient Descent"
      ],
      "metadata": {
        "id": "tjRWicX-HERo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Executando a validação cruzada\n",
        "mean_accuracy, mean_class_accuracies, std_accuracy, std_class_accuracies = cross_validate(X_normalized_vehicle, y_vehicle_one_hot, n_folds, learning_rate, iterations, 'sgd')\n",
        "\n",
        "print('Gradient Descent')\n",
        "print(f\"Média Global: {mean_accuracy}\")\n",
        "print(f\"Desvio Padrão Global: {std_accuracy}\")\n",
        "for i in range(len(mean_class_accuracies)):\n",
        "    print(f\"Média da Acurácia para Classe {i}: {mean_class_accuracies[i]}\")\n",
        "    print(f\"Desvio Padrão da Acurácia para Classe {i}: {std_class_accuracies[i]}\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7BU0J0QCKkh",
        "outputId": "4898bba7-b49c-48c2-b5f8-09cba7e7454f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Descent\n",
            "Média Global: 0.4428571428571429\n",
            "Desvio Padrão Global: 0.06135285107964346\n",
            "Média da Acurácia para Classe 0: 0.1405570818070818\n",
            "Desvio Padrão da Acurácia para Classe 0: 0.05353814162007227\n",
            "Média da Acurácia para Classe 1: 0.0\n",
            "Desvio Padrão da Acurácia para Classe 1: 0.0\n",
            "Média da Acurácia para Classe 2: 0.7558506776023755\n",
            "Desvio Padrão da Acurácia para Classe 2: 0.1257245610800545\n",
            "Média da Acurácia para Classe 3: 0.9067105263157893\n",
            "Desvio Padrão da Acurácia para Classe 3: 0.07134636089496375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análise do discriminante Gaussiano"
      ],
      "metadata": {
        "id": "F7v84Bh6HMOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gaussian_discriminant_analysis(X_train, y_train):\n",
        "    # Obtendo as classes únicas\n",
        "    classes = np.arange(y_train.shape[1])\n",
        "\n",
        "    # Inicializando variáveis para armazenar parâmetros de cada classe\n",
        "    mus = {}\n",
        "    covs = {}\n",
        "    priors = {}\n",
        "\n",
        "    for c in classes:\n",
        "        X_c = X_train[y_train[:, c] == 1]\n",
        "        mus[c] = np.mean(X_c, axis=0)\n",
        "        covs[c] = np.cov(X_c, rowvar=False)\n",
        "        priors[c] = len(X_c) / len(X_train)\n",
        "\n",
        "    # Calcular a matriz de covariância comum\n",
        "    cov_shared = sum(priors[c] * covs[c] for c in classes)\n",
        "    inv_cov_shared = np.linalg.inv(cov_shared)\n",
        "    det_cov_shared = np.linalg.det(cov_shared)\n",
        "\n",
        "    consts = {c: -0.5 * np.log(det_cov_shared) + np.log(priors[c]) for c in classes}\n",
        "\n",
        "    return mus, inv_cov_shared, consts\n",
        "\n"
      ],
      "metadata": {
        "id": "tamE-5P2D0Dc"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_gda(X, mus, inv_cov_shared, consts):\n",
        "    # Calcular as funções discriminantes para cada classe\n",
        "    g = {c: -0.5 * np.sum((X - mus[c]) @ inv_cov_shared * (X - mus[c]), axis=1) + consts[c] for c in mus}\n",
        "\n",
        "    # Comparar as funções discriminantes e fazer as previsões\n",
        "    y_pred = np.argmax(np.column_stack(list(g.values())), axis=1)\n",
        "\n",
        "    return y_pred\n"
      ],
      "metadata": {
        "id": "lIXKzs-4E_ma"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model_gda(X_train, y_train, X_test, y_test):\n",
        "    # Treinando o modelo GDA\n",
        "    mus, inv_cov_shared, consts = gaussian_discriminant_analysis(X_train, y_train)\n",
        "\n",
        "    # Fazendo previsões no conjunto de teste\n",
        "    y_pred = predict_gda(X_test, mus, inv_cov_shared, consts)\n",
        "\n",
        "    # Calculando acurácia global\n",
        "    accuracy = np.mean(y_pred == y_test.argmax(axis=1))\n",
        "\n",
        "    # Calculando a acurácia por classe\n",
        "    class_accuracies = []\n",
        "    for c in range(y_train.shape[1]):\n",
        "        class_accuracy = np.mean((y_pred == y_test.argmax(axis=1))[y_test[:, c] == 1])\n",
        "        class_accuracies.append(class_accuracy)\n",
        "\n",
        "    return accuracy, class_accuracies\n"
      ],
      "metadata": {
        "id": "ofHUP08_FCTu"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo o número de folds para validação cruzada\n",
        "n_folds = 10\n",
        "\n",
        "# Função para realizar a validação cruzada\n",
        "def cross_validate_gda(X, y, n_folds):\n",
        "    fold_size = len(X) // n_folds\n",
        "    accuracies = []\n",
        "    class_accuracies_list = []\n",
        "\n",
        "    for fold in range(n_folds):\n",
        "        start = fold * fold_size\n",
        "        end = start + fold_size\n",
        "\n",
        "        X_test = X[start:end]\n",
        "        y_test = y[start:end]\n",
        "\n",
        "        X_train = np.concatenate((X[:start], X[end:]), axis=0)\n",
        "        y_train = np.concatenate((y[:start], y[end:]), axis=0)\n",
        "\n",
        "        accuracy, class_accuracies = evaluate_model_gda(X_train, y_train, X_test, y_test)\n",
        "        accuracies.append(accuracy)\n",
        "        class_accuracies_list.append(class_accuracies)\n",
        "\n",
        "    mean_accuracy = np.mean(accuracies)\n",
        "    mean_class_accuracies = np.mean(class_accuracies_list, axis=0)\n",
        "\n",
        "    std_accuracy = np.std(accuracies)\n",
        "    std_class_accuracies = np.std(class_accuracies_list, axis=0)\n",
        "\n",
        "    return mean_accuracy, mean_class_accuracies, std_accuracy, std_class_accuracies\n",
        "\n",
        "# Executando a validação cruzada\n",
        "mean_accuracy, mean_class_accuracies, std_accuracy, std_class_accuracies = cross_validate_gda(X_normalized_vehicle, y_vehicle_one_hot, n_folds)\n",
        "\n",
        "print(f\"Média Global: {mean_accuracy}\")\n",
        "print(f'Desvio Padrão Global: {std_accuracy}')\n",
        "\n",
        "for i in range(len(mean_class_accuracies)):\n",
        "    print(f\"Média da Acurácia para Classe {i}: {mean_class_accuracies[i]}\")\n",
        "    print(f'Desvio Padrão {i}: {std_class_accuracies[i]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3ejYdc2wgkq",
        "outputId": "e89cb92a-9969-4798-eb36-7eb52f5ab76f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média Global: 0.7773809523809524\n",
            "Desvio Padrão Global: 0.03651871821470944\n",
            "Média da Acurácia para Classe 0: 0.9664845339845339\n",
            "Desvio Padrão 0: 0.030301028068568773\n",
            "Média da Acurácia para Classe 1: 0.5969163663489111\n",
            "Desvio Padrão 1: 0.10416027273200833\n",
            "Média da Acurácia para Classe 2: 0.5823343720296714\n",
            "Desvio Padrão 2: 0.12804738627234435\n",
            "Média da Acurácia para Classe 3: 0.9573675610595116\n",
            "Desvio Padrão 3: 0.055280406998010206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes"
      ],
      "metadata": {
        "id": "nfGB_PIcHW8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_naive_bayes(X_train, y_train):\n",
        "    classes = np.unique(y_train.argmax(axis=1))\n",
        "    class_priors = {}\n",
        "    means = {}\n",
        "    stds = {}\n",
        "\n",
        "    for c in classes:\n",
        "        X_c = X_train[y_train[:, c] == 1]\n",
        "        class_priors[c] = len(X_c) / len(X_train)\n",
        "        means[c] = np.mean(X_c, axis=0)\n",
        "        stds[c] = np.std(X_c, axis=0)\n",
        "\n",
        "    return class_priors, means, stds\n",
        "\n"
      ],
      "metadata": {
        "id": "9aUPyf2OFeh1"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_probability(x, mean, std):\n",
        "    exponent = np.exp(-((x - mean) ** 2) / (2 * (std ** 2)))\n",
        "    return np.prod((1 / (np.sqrt(2 * np.pi) * std)) * exponent)\n"
      ],
      "metadata": {
        "id": "Es52XMr0yeGZ"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_naive_bayes(X_test, class_priors, means, stds):\n",
        "    predictions = []\n",
        "    for x in X_test:\n",
        "        class_probabilities = {}\n",
        "        for c in class_priors:\n",
        "            class_probabilities[c] = class_priors[c] * calculate_probability(x, means[c], stds[c])\n",
        "        predicted_class = max(class_probabilities, key=class_probabilities.get)\n",
        "        predictions.append(predicted_class)\n",
        "\n",
        "    return np.array(predictions)\n",
        "\n"
      ],
      "metadata": {
        "id": "mQ1sBfoXygWG"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model_naive_bayes(X_train, y_train, X_test, y_test):\n",
        "    # Treinando o modelo Naive Bayes\n",
        "    class_priors, means, stds = fit_naive_bayes(X_train, y_train)\n",
        "\n",
        "    # Fazendo previsões no conjunto de teste\n",
        "    y_pred = predict_naive_bayes(X_test, class_priors, means, stds)\n",
        "\n",
        "    # Calculando acurácia global\n",
        "    accuracy = np.mean(y_pred == y_test.argmax(axis=1))\n",
        "\n",
        "    # Calculando a acurácia por classe\n",
        "    class_accuracies = []\n",
        "    for c in range(y_train.shape[1]):\n",
        "        class_accuracy = np.mean((y_pred == y_test.argmax(axis=1))[y_test[:, c] == 1])\n",
        "        class_accuracies.append(class_accuracy)\n",
        "\n",
        "    return accuracy, class_accuracies\n",
        "\n"
      ],
      "metadata": {
        "id": "fGf9G5Zdyiko"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo o número de folds para validação cruzada\n",
        "n_folds = 10\n",
        "\n",
        "# Função para realizar a validação cruzada\n",
        "def cross_validate_naive_bayes(X, y, n_folds):\n",
        "    fold_size = len(X) // n_folds\n",
        "    accuracies = []\n",
        "    class_accuracies_list = []\n",
        "\n",
        "    for fold in range(n_folds):\n",
        "        start = fold * fold_size\n",
        "        end = start + fold_size\n",
        "\n",
        "        X_test = X[start:end]\n",
        "        y_test = y[start:end]\n",
        "\n",
        "        X_train = np.concatenate((X[:start], X[end:]), axis=0)\n",
        "        y_train = np.concatenate((y[:start], y[end:]), axis=0)\n",
        "\n",
        "        accuracy, class_accuracies = evaluate_model_naive_bayes(X_train, y_train, X_test, y_test)\n",
        "        accuracies.append(accuracy)\n",
        "        class_accuracies_list.append(class_accuracies)\n",
        "\n",
        "    mean_accuracy = np.mean(accuracies)\n",
        "    mean_class_accuracies = np.mean(class_accuracies_list, axis=0)\n",
        "\n",
        "    std_accuracy = np.std(accuracies)\n",
        "    std_class_accuracies = np.std(class_accuracies_list, axis=0)\n",
        "\n",
        "    return mean_accuracy, mean_class_accuracies, std_accuracy, std_class_accuracies\n",
        "\n",
        "# Executando a validação cruzada\n",
        "mean_accuracy, mean_class_accuracies, std_accuracy, std_class_accuracies = cross_validate_naive_bayes(X_normalized_vehicle, y_vehicle_one_hot, n_folds)\n",
        "\n",
        "print(f\"Média Global: {mean_accuracy}\")\n",
        "print(f'Desvio Padrão Global: {std_accuracy}')\n",
        "\n",
        "for i in range(len(mean_class_accuracies)):\n",
        "    print(f\"Média da Acurácia para Classe {i}: {mean_class_accuracies[i]}\")\n",
        "    print(f'Desvio Padrão {i}: {std_class_accuracies[i]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1iH3hCWyk97",
        "outputId": "0aa58183-6931-4678-947a-1a77f2399203"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média Global: 0.4607142857142857\n",
            "Desvio Padrão Global: 0.04822530738221212\n",
            "Média da Acurácia para Classe 0: 0.1693040293040293\n",
            "Desvio Padrão 0: 0.11984354652352562\n",
            "Média da Acurácia para Classe 1: 0.419102116801925\n",
            "Desvio Padrão 1: 0.06824332767855044\n",
            "Média da Acurácia para Classe 2: 0.40756658435488147\n",
            "Desvio Padrão 2: 0.08479422976772243\n",
            "Média da Acurácia para Classe 3: 0.8830503955968354\n",
            "Desvio Padrão 3: 0.08652589937380051\n"
          ]
        }
      ]
    }
  ]
}